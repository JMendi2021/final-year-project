{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze Interception\n",
    "This notebook takes in three files taken from the Pupil Recordings you have exported in Pupil Player. These are:\n",
    "- `gaze_positions.csv` (contains raw data in regards to the gaze made throughout the recording)\n",
    "- `info.player.json` (contains system and sync time used to format the recording timestamps)\n",
    "- `fixations.csv` (contains events of where fixations has occured throughout the experiment)\n",
    "- `annotations.csv` (contains annotations created in the experiment used for object interception/spawn, regions of observation, and when the experiment has begin and ended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# File Paths\n",
    "info_player_filePath = 'experiment_source/info.player.json'\n",
    "gaze_csv_filePath = 'experiment_source/gaze_positions.csv'\n",
    "annotations_filepath = 'experiment_source/annotations.csv'\n",
    "fixation_filepath = 'experiment_source/fixations.csv'\n",
    "\n",
    "# Contrasting Colours\n",
    "CONTRASTING_COLURS = ['#011627', '#2ec4b6', '#e71d36', '#ff9f1c']\n",
    "current_colour_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DataFrame from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the `info.player` JSON to retrieve `start_time_synced_s` and `start_time_system_s`. This is used to format the timestamp correctly to indicate time throughout the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_offset(filepath):\n",
    "    with open(info_player_filePath, 'r') as file:\n",
    "        data = json.load(file)  \n",
    "    return data.get('start_time_system_s') - data.get('start_time_synced_s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, reading the gaze_position.csv file to obtain base data, formating time, calculating smoothed positions, and angular distance and velocity of each timestamp. And removing data that contains infinte or NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 7629 gaze positions\n"
     ]
    }
   ],
   "source": [
    "# Calculate angular distance given Cartesian coordinates (x, y)\n",
    "def calculate_angular_distance(x, y):\n",
    "    return np.arctan2(y, x)\n",
    "\n",
    "# Calculate velocity given angular distance and corresponding timestamps.\n",
    "def calculate_velocity(angular_distance, timestamp):\n",
    "    time_diff = np.diff(timestamp)\n",
    "    angular_distance_diff = np.diff(angular_distance)\n",
    "    velocity = angular_distance_diff / time_diff\n",
    "    return np.concatenate(([np.nan], velocity))\n",
    "\n",
    "\n",
    "# Applies Rolling Medium over the input field, and exports that into the output field\n",
    "def smooth_data(df, input, output, window_size=0):\n",
    "    df[output] = df[input].rolling(window=window_size).median()\n",
    "    return df\n",
    "\n",
    "def obtain_gaze_data(filepath: str, window=10, offset=0):\n",
    "    csv_df = pd.read_csv(filepath)\n",
    "    results_df = pd.DataFrame(columns=['gaze_timestamp',\n",
    "                                       'time',\n",
    "                                       'norm_pos_x', \n",
    "                                       'norm_pos_y', \n",
    "                                       'angular_distance',\n",
    "                                       'angular_velocity',\n",
    "                                       'movement_type',\n",
    "                                       'smoothed_norm_pos_x', \n",
    "                                       'smoothed_norm_pos_y',\n",
    "                                       'smoothed_angular_distance',\n",
    "                                       'smoothed_angular_velocity',\n",
    "                                       'smoothed_movement_type'])\n",
    "\n",
    "    # Copy the data from csv of necessary fields\n",
    "    results_df['gaze_timestamp'] = csv_df['gaze_timestamp']\n",
    "    results_df['norm_pos_x'] = csv_df['norm_pos_x']\n",
    "    results_df['norm_pos_y'] = csv_df['norm_pos_y']\n",
    "    results_df['movement_type'] = 'None'\n",
    "    results_df['smoothed_movement_type'] = 'None'\n",
    "    \n",
    "    # Populating the time field by adding the offset and then subtracting the minimum time to start from 0\n",
    "    results_df['time'] = results_df['gaze_timestamp'] + offset\n",
    "    results_df['time'] -= results_df['time'].min()\n",
    "\n",
    "    # Using rolling mean to smooth the data and to rmeove as many extreme outliers that has been missed by Pupil Export\n",
    "    results_df['smoothed_norm_pos_x'] = results_df['norm_pos_x'].rolling(window).median()\n",
    "    results_df['smoothed_norm_pos_y'] = results_df['norm_pos_y'].rolling(window).median()\n",
    "\n",
    "    # Calculating the angular distance for each x and y position for both smoothed and un-smoothed\n",
    "    results_df['angular_distance'] = calculate_angular_distance(results_df['norm_pos_x'], results_df['norm_pos_y'])\n",
    "    results_df['smoothed_angular_distance'] = calculate_angular_distance(results_df['smoothed_norm_pos_x'], results_df['smoothed_norm_pos_y'])\n",
    "\n",
    "    # Calculating the angular velocity for both smooth and un-smoothed angular distances over time\n",
    "    results_df['angular_velocity'] = calculate_velocity(results_df['angular_distance'], results_df['time'])\n",
    "    results_df['smoothed_angular_velocity'] = calculate_velocity(results_df['smoothed_angular_distance'], results_df['time'])\n",
    "\n",
    "    # Dropping NaN records and the `gaze_timestamp` field\n",
    "    results_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    results_df.dropna(inplace=True)\n",
    "    results_df = results_df.drop('gaze_timestamp', axis=1) # Remove the `gaze_timestamp` as that is not needed anymore\n",
    "\n",
    "    return results_df\n",
    "\n",
    "window_size=10\n",
    "offset = obtain_offset(info_player_filePath)\n",
    "gaze_df = obtain_gaze_data(gaze_csv_filePath, window=window_size, offset=offset)\n",
    "print(f'There is a total of {len(gaze_df)} gaze positions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Smooth Pursuit\n",
    "Smooth pursuit occurs when the eyes tracks an moving object. There is roughly a constant velocity as the angular distance changes slowly, whereas Saccades are almost instant. We choose regions of the line where the change in velocity is under a threshold, and the change of angular distance is small enough to indicate the eyes moving between positions slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Smooth Pursuit Movements: 5641\n"
     ]
    }
   ],
   "source": [
    "def predict_smooth_pursuit(df, threshold_velocity=0.2, angular_distance_threshold=2e-4):\n",
    "    pursuit_regions_velocity = np.abs(np.gradient(df['angular_velocity'])) < threshold_velocity\n",
    "    pursuit_regions_distance = np.abs(np.gradient(df['angular_distance'])) > angular_distance_threshold\n",
    "    pursuit_regions = (pursuit_regions_velocity) & (pursuit_regions_distance)\n",
    "    df['movement_type'] = np.where((df['movement_type'] == 'None') & pursuit_regions, 'Smooth Pursuit', df['movement_type'])\n",
    "    \n",
    "    pursuit_regions_smoothed_velocity = np.abs(np.gradient(df['smoothed_angular_velocity'])) < threshold_velocity\n",
    "    pursuit_regions_smoothed_distance = np.abs(np.gradient(df['smoothed_angular_distance'])) > angular_distance_threshold\n",
    "    pursuit_regions_smoothed = (pursuit_regions_smoothed_velocity) & (pursuit_regions_smoothed_distance)\n",
    "    df['smoothed_movement_type'] = np.where((df['smoothed_movement_type'] == 'None') & pursuit_regions_smoothed, 'Smooth Pursuit', df['smoothed_movement_type'])\n",
    "\n",
    "predict_smooth_pursuit(gaze_df, threshold_velocity=0.2, angular_distance_threshold=2e-4)\n",
    "smooth_pursuit = gaze_df[(gaze_df['movement_type'] == 'Smooth Pursuit') | (gaze_df['smoothed_movement_type'] == 'Smooth Pursuit')]\n",
    "print(f'Total Smooth Pursuit Movements: {len(smooth_pursuit)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Saccades\n",
    "Based on the research from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1190820/pdf/jphysiol00502-0164.pdf, Saccadic Movements have a stereotypical velocity graph where large peaks indicates a fast movement between two points (saccades). These are almost like straight lines between points. We can say that if the velocity between two  points exceeds a threshold, then this is most possibly a saccadic movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Saccadic Movements: 2367\n"
     ]
    }
   ],
   "source": [
    "def predict_saccades(df, threshold_velocity=0.6):\n",
    "    saccade_regions_high = df['angular_velocity'] > threshold_velocity\n",
    "    accade_regions_low = df['angular_velocity'] < -threshold_velocity\n",
    "    saccade_regions = saccade_regions_high | accade_regions_low\n",
    "    df['movement_type'] = np.where(saccade_regions, 'Saccades', 'None')\n",
    "    \n",
    "    saccade_regions_high = df['smoothed_angular_velocity'] > threshold_velocity\n",
    "    accade_regions_low = df['smoothed_angular_velocity'] < -threshold_velocity\n",
    "    saccade_regions = saccade_regions_high | accade_regions_low\n",
    "    df['smoothed_movement_type'] = np.where((df['smoothed_movement_type'].isin(['None', 'Smooth Pursuit'])) & saccade_regions, 'Saccades', df['smoothed_movement_type'])\n",
    "\n",
    "predict_saccades(gaze_df, threshold_velocity=0.6)\n",
    "saccades = gaze_df[(gaze_df['movement_type'] == 'Saccades') | (gaze_df['smoothed_movement_type'] == 'Saccades')]\n",
    "print(f'Total Saccadic Movements: {len(saccades)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Fixation\n",
    "Fixations are defined as gaze remain fixed around a stationary point. It is not directly fixed but the user gazes around the same point for a long period of time.\n",
    "\n",
    "Pupil Player provides another csv file called `fixations` which identifies the timestamp of when a fixation occurs, and how long it can take. The function `plot_fixation_graph` takes regions starting from whatever second the fixation starts up until the end of the fixation indicated by by the `duration` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Fixation Movements: 0\n"
     ]
    }
   ],
   "source": [
    "def predict_fixation(df, offset, time_offset=0.10, filepath='fixations.csv'):\n",
    "    fixations_df = pd.read_csv(filepath)\n",
    "    fixations_df['time'] = fixations_df['start_timestamp'] + offset\n",
    "    fixations_df['time'] -= fixations_df['time'].min()\n",
    "\n",
    "    for _, fixation in fixations_df.iterrows():\n",
    "        start_time = fixation['time']\n",
    "        duration = (fixation['duration'] / 1000.0) - time_offset  # Convert into seconds\n",
    "\n",
    "        # Mark rows within the fixation region as 'Fixation' in both columns\n",
    "        fixation_regions = (df['time'] >= start_time) & (df['time'] <= start_time + duration)\n",
    "        df.loc[fixation_regions, 'movement_type'] = 'Fixation'\n",
    "        df.loc[fixation_regions, 'smoothed_movement_type'] = 'Fixation'\n",
    "\n",
    "predict_fixation(gaze_df, offset, time_offset=0.10, filepath=fixation_filepath)\n",
    "fixation = gaze_df[(gaze_df['movement_type'] == 'Fixation') | (gaze_df['smoothed_movement_type'] == 'Fixation')]\n",
    "print(f'Total Fixation Movements: {len(fixation)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating Annotations\n",
    "Using the annotation.csv file, we want to generate new csv files that contains the following: object information, regions of observation, and experiment start/end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhund\\AppData\\Local\\Temp\\ipykernel_4244\\459282757.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  regions_df = pd.concat([regions_df, pd.DataFrame({'id': [current_obj_id], 'start_time': [start_time], 'end_time': [end_time]})], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def analyse_annotations(annotations_csv_filepath, offset, fill_threshold=1):\n",
    "    # This works through the the annotation and finds the following:\n",
    "    # What object each data point is looking at\n",
    "    # When an object spawns and intercepted\n",
    "\n",
    "    # Group every spawn and interception into a single record (not all spawn may have an interception), could group by object ID?\n",
    "    annotations_df = pd.read_csv(annotations_csv_filepath)\n",
    "    \n",
    "    # Format the timestamp into time relative to the experiment\n",
    "    annotations_df['time'] = annotations_df['timestamp'] + offset\n",
    "    annotations_df['time'] -= annotations_df['time'].min()\n",
    "\n",
    "    # Filter only the data that contains 'Intercepted' or 'Spawning'.\n",
    "    # Each object has their own spawning and interception time, could create records of these two\n",
    "    # We can utilise this data as our own way to simplify the visualising and also finding TTC\n",
    "\n",
    "    # Filter rows with 'Intercepted' or 'Spawning' label\n",
    "    object_annotations = annotations_df[annotations_df['label'].isin(['Intercepted', 'Spawning'])]\n",
    "    objects_df = object_annotations.pivot(index='id', columns='label', values='time')\n",
    "    objects_df.reset_index(inplace=True)\n",
    "\n",
    "    # If any object does not have both 'Spawning' and 'Intercepted' events, fill NaN with appropriate values\n",
    "    objects_df.fillna({'spawning_timestamp': pd.NaT, 'intercepted_timestamp': pd.NaT}, inplace=True)\n",
    "\n",
    "    # Now, create a new dataframe which stores when a user is looking at a specific region\n",
    "\n",
    "    # Obtains all records with the 'Looking At' label\n",
    "    looking_at_df = annotations_df[annotations_df['label'].isin(['Looking At'])]\n",
    "\n",
    "    # Initialise an empty DataFrame to store regions\n",
    "    regions_df = pd.DataFrame(columns=['id', 'start_time', 'end_time'])\n",
    "\n",
    "    # Initialise variables for tracking consecutive points\n",
    "    current_obj_id = None\n",
    "    start_time = None\n",
    "\n",
    "    # Iterate through each row in the 'Looking At' dataframe\n",
    "    for _, row in looking_at_df.iterrows():\n",
    "        obj_id = row['id']\n",
    "        timestamp = row['time']\n",
    "\n",
    "        # Check if it's the same object and within the threshold seconds\n",
    "        if obj_id == current_obj_id and start_time is not None and timestamp - start_time <= fill_threshold: \n",
    "            end_time = timestamp # Update the end time for the current region\n",
    "        else:\n",
    "            # A new region is created when the next ID does not match the current region's ID OR if the time between two points is greater than the threshold (indicating it's a new region for the same ID)\n",
    "            if current_obj_id is not None and start_time is not None:\n",
    "                regions_df = pd.concat([regions_df, pd.DataFrame({'id': [current_obj_id], 'start_time': [start_time], 'end_time': [end_time]})], ignore_index=True)\n",
    "\n",
    "            # Update tracking variables for the next iteration\n",
    "            current_obj_id = obj_id\n",
    "            start_time = timestamp\n",
    "            end_time = timestamp\n",
    "\n",
    "    # Add the last region after the loop\n",
    "    if current_obj_id is not None and start_time is not None:\n",
    "        regions_df = pd.concat([regions_df, pd.DataFrame({'id': [current_obj_id], 'start_time': [start_time], 'end_time': [end_time]})], ignore_index=True)\n",
    "\n",
    "    # May want to include the Experiment Start and End lines as a JSON\n",
    "    start_time = annotations_df.loc[(annotations_df['label'] == 'Experiment Started'), 'time'].values\n",
    "    end_time = annotations_df.loc[(annotations_df['label'] == 'Experiment Ended'), 'time'].values\n",
    "\n",
    "    experiment_info = {\n",
    "        'Start': start_time.item(),\n",
    "        'End': end_time.item()\n",
    "    }\n",
    "\n",
    "    return objects_df, regions_df, experiment_info\n",
    "\n",
    "objects_df, regions_df, experiment_info = analyse_annotations(annotations_filepath, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding TTC per interception\n",
    "This function only works if we have incorporated the annotation as we need the interception that has been made. This iterates through each interceptiom find all the points that falls below the time that interception has been made and take the most recent saccadic movement to calculate the Time-To-Contact by taking the difference between\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_TTC(gaze_df, objects_df):\n",
    "    results = []\n",
    "\n",
    "    for index, row in objects_df.iterrows():\n",
    "        # Extract the 'Intercepted' time\n",
    "        intercepted_time = row['Intercepted']\n",
    "        \n",
    "        # Filter gaze_df based on the condition where 'time' is less than the intercepted_time\n",
    "        filtered_gaze_df = gaze_df[gaze_df['time'] < intercepted_time]\n",
    "\n",
    "        # Obtain all the records where the movement type is Saccades\n",
    "        smoothed_saccadic_gaze_df = filtered_gaze_df[filtered_gaze_df['smoothed_movement_type'] == \"Saccades\"]\n",
    "        saccadic_gaze_df = filtered_gaze_df[filtered_gaze_df['movement_type'] == \"Saccades\"]\n",
    "\n",
    "        # Obtains the latest saccadic movement before the intercepted time\n",
    "        recent_saccade = saccadic_gaze_df['time'].max()\n",
    "        smoothed_recent_saccade = smoothed_saccadic_gaze_df['time'].max()\n",
    "\n",
    "        # Calculate the saccadic movement before the interception was made which is the difference between latest saccade and interception\n",
    "        time_to_contact = intercepted_time - recent_saccade\n",
    "        smooth_time_to_contact = intercepted_time - smoothed_recent_saccade\n",
    "        results.append({\n",
    "            'Object_ID': index+1, \n",
    "            'Interception': intercepted_time, \n",
    "            'Recent Saccade': recent_saccade, \n",
    "            'Time to Contact': time_to_contact,\n",
    "            'Smoothed Recent Saccade': smoothed_recent_saccade,\n",
    "            'Smoothed Time to Contact': smooth_time_to_contact})\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "ttc_df = find_TTC(gaze_df, objects_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data\n",
    "To be used for later or with the Visualier, this exports the dataframe and an json containing the offset for annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows the dataframe to be exported as a csv file of a given name as well as a JSON file that stores the offset if the graph was to be used again\n",
    "def export_gaze_data(gaze, objects, regions, ttc, experiment_info):\n",
    "    \n",
    "    output_directory = 'analysed_output'\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    output_directory = 'visualise_source'\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Saves a copy into the analysed output\n",
    "    gaze.to_csv(f'analysed_output/gaze.csv', index=False)\n",
    "    objects.to_csv(f'analysed_output/objects.csv', index=False)\n",
    "    regions.to_csv(f'analysed_output/regions.csv', index=False)\n",
    "    ttc.to_csv(f'analysed_output/ttc.csv', index=False)\n",
    "\n",
    "    with open('analysed_output/experiment_info.json', 'w') as json_file:\n",
    "        json.dump(experiment_info, json_file)\n",
    "\n",
    "    # Saves another copy into the visualise_source \n",
    "    gaze.to_csv(f'visualise_source/gaze.csv', index=False)\n",
    "    objects.to_csv(f'visualise_source/objects.csv', index=False)\n",
    "    regions.to_csv(f'visualise_source/regions.csv', index=False)\n",
    "    ttc.to_csv(f'visualise_source/ttc.csv', index=False)\n",
    "\n",
    "    with open('visualise_source/experiment_info.json', 'w') as json_file:\n",
    "        json.dump(experiment_info, json_file)\n",
    "\n",
    "export_gaze_data(gaze_df, objects_df, regions_df, ttc_df, experiment_info) # Exporting the dataframe as a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze Visualiser\n",
    "This notebook takes in one files taken from the Pupil Recordings `annotations.csv` and a `offset.json`, and the data compiled from the analyser from the analyser. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# File Paths\n",
    "annotations_filepath = 'source/annotations.csv'\n",
    "gaze_filepath = ''\n",
    "offset_filepath = 'offset.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the offset for correct time format and finding the filename of the dat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_offset(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)  \n",
    "    return data.get('offset')\n",
    "\n",
    "def find_gaze_csv(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            return filename\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a visual representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the difference between both non-smoothed and smoothed versions of `norm_pos_x` and `norm_pos_y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_norm_positions(df):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    axs[0].plot(df['time'], df['norm_pos_x'], label='Original norm_pos_x')\n",
    "    axs[0].plot(df['time'], df['smoothed_norm_pos_x'], label=f'Smoothed norm_pos_x (window={10})', linestyle='--')\n",
    "    axs[0].set_title('Norm_pos_x')\n",
    "\n",
    "    axs[1].plot(df['time'], df['norm_pos_y'], label='Original norm_pos_y')\n",
    "    axs[1].plot(df['time'], df['smoothed_norm_pos_y'], label=f'Smoothed norm_pos_y (window={10})', linestyle='--')\n",
    "    axs[1].set_title('Norm_pos_y')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Position')\n",
    "        ax.legend()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Angular Distance agaisnt Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `angular_distance` or `smoothed_angular_distance` plot an angular distance x time grapgh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot angular distance data from a DataFrame against time.\n",
    "def plot_angular_distance(fig, ax, df, use_smooth=False, show_both=False):\n",
    "\n",
    "    if show_both:\n",
    "        ax.plot(df['time'], df['angular_distance'], label='Gaze Angular Distance',)\n",
    "        ax.plot(df['time'], df['smoothed_angular_distance'], label=f'Angular Distance', linestyle='--')\n",
    "    else:\n",
    "        if use_smooth:\n",
    "            ax.plot(df['time'], df['smoothed_angular_distance'], label=f'Angular Distance', color='orange')\n",
    "        else:\n",
    "            ax.plot(df['time'], df['angular_distance'], label='Gaze Angular Distance', color='orange')\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Angular Distance (rad)', color='black')\n",
    "    ax.legend(loc='lower right')\n",
    "    fig.suptitle('Interception Experiment')\n",
    "    fig.tight_layout()\n",
    "\n",
    "# Defining a graph to work with throughout the script:\n",
    "# combined_figure, ax3 = plt.subplots(figsize=(16, 8))\n",
    "# plot_angular_distance(combined_figure, ax3, gaze_df, show_both=True)\n",
    "# combined_figure.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_velocity_graph(df, use_smooth=False):\n",
    "    if use_smooth:\n",
    "        source_velocity = 'smoothed_angular_velocity'\n",
    "    else:\n",
    "        source_velocity = 'angular_velocity'\n",
    "    \n",
    "    velocities = df[source_velocity]\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.plot(df['time'], velocities, label=f'{velocities}',)\n",
    "\n",
    "    plt.title('Angular Velocity x Time Graph')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Angular Velocity (rad/s)')\n",
    "    # plt.ylabel('Gaze Position')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Eye Movements\n",
    "Within the dataframe, there is a field called `movement_type` where we identify which one of the three eye movements (Saccade, Fixations, and Smooth Pursuit) base on velocities and provided csv file from Pupil Lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Regions of Saccades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_saccades(ax, df, use_smooth=False):\n",
    "    if use_smooth:\n",
    "        source_distance = 'smoothed_angular_distance'\n",
    "        movement_type= 'smoothed_movement_type'\n",
    "    else:\n",
    "        source_distance = 'angular_distance'\n",
    "        movement_type = 'movement_type'\n",
    "\n",
    "    distances = df[source_distance]\n",
    "    saccade_regions = df[movement_type] == 'Saccades'\n",
    "\n",
    "    ax.plot(df['time'], np.where(saccade_regions, distances, np.nan), color='red', label='Saccade Line')\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Regions of Smooth Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smooth_pursuits(ax, df, use_smooth=False):\n",
    "    if use_smooth:\n",
    "        source_distance = 'smoothed_angular_distance'\n",
    "        movement_type_column = 'smoothed_movement_type'\n",
    "    else:\n",
    "        source_distance = 'angular_distance'\n",
    "        movement_type_column = 'movement_type'\n",
    "\n",
    "    distances = df[source_distance]\n",
    "    smooth_pursuit_regions = df[movement_type_column] == 'Smooth Pursuit'\n",
    "\n",
    "    # Plot for Smooth Pursuit Data\n",
    "    ax.plot(df['time'], np.where(smooth_pursuit_regions, distances, np.nan), color='green', label='Smooth Pursuit')\n",
    "    ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Regions of Fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fixations(ax, df, use_smooth=False):\n",
    "    if use_smooth:\n",
    "        source_distance = 'smoothed_angular_distance'\n",
    "        movement_type= 'smoothed_movement_type'\n",
    "    else:\n",
    "        source_distance = 'angular_distance'\n",
    "        movement_type = 'movement_type'\n",
    "\n",
    "    distances = df[source_distance]\n",
    "    fixation_regions = df[movement_type] == 'Fixation'\n",
    "\n",
    "    ax.plot(df['time'], np.where(fixation_regions, distances, np.nan), color='blue', label='Fixation')\n",
    "    ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the identification functions\n",
    "This would combine each of the function and allow the user control on what they wish to present on the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(gaze_df, use_smooth, fixations=False, smooth_pursuits=False, saccades=False):\n",
    "    figure, ax = plt.subplots(figsize=(16, 8))\n",
    "    plot_angular_distance(figure, ax, gaze_df, use_smooth=use_smooth)\n",
    "\n",
    "    if fixations:\n",
    "        plot_fixations(ax, gaze_df, use_smooth=use_smooth)\n",
    "    \n",
    "    if smooth_pursuits:\n",
    "        plot_smooth_pursuits(ax, gaze_df, use_smooth=use_smooth)\n",
    "\n",
    "    if saccades:\n",
    "        plot_saccades(ax, gaze_df, use_smooth=use_smooth)\n",
    "\n",
    "    return figure, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Annotations to the graph\n",
    "The annotation is compiled of different events that has occured throughout the event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`add_annotations` looks at a gieven filepath to an `annotation_csv` file and uses `labels` and `timestamp` to determine where to plot events on a Angular Distance Time Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a contrasting colour palette to easily help identify regions\n",
    "def choose_colour():\n",
    "    global current_colour_index\n",
    "    colour = CONTRASTING_COLURS[current_colour_index]\n",
    "    current_colour_index = (current_colour_index + 1) % len(CONTRASTING_COLURS)\n",
    "    return colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate a random RGB color tuple.\n",
    "def generate_random_color():\n",
    "    return (random.random(), random.random(), random.random())\n",
    "\n",
    "# Draw lines and labels representing spawned objects and interceptions on the given axis.\n",
    "def draw_objects_and_interceptions(ax, spawn_timestamps, interception_timestamps, annotations_df, obstacle_ids):\n",
    "    object_colors = {}\n",
    "\n",
    "    # Handle Spawning annotations\n",
    "    for timestamp, obj_id in zip(spawn_timestamps, annotations_df.loc[annotations_df['label'] == ('Spawning'), 'id']):\n",
    "\n",
    "        # Checks if the current annotation is refering to an Obstacle objectType by filtering the annotations_df for the Object ID and retrieving the first 'objectType' (which there should only be one)\n",
    "        obj_type = annotations_df.loc[(annotations_df['label'] == 'Spawning') & (annotations_df['id'] == obj_id), 'objectType'].values[0] if 'objectType' in annotations_df.columns else None\n",
    "        if obj_type == 'Obstacle' and obj_id in obstacle_ids:\n",
    "            draw_object_line(ax, timestamp, obj_id, object_colors, is_interception=False)\n",
    "\n",
    "    # Handle Interception annotations\n",
    "    for timestamp, obj_id in zip(interception_timestamps, annotations_df.loc[annotations_df['label'] == 'Intercepted', 'id']):\n",
    "        obj_type = annotations_df.loc[(annotations_df['label'] =='Intercepted') & (annotations_df['id'] == obj_id),'objectType'].values[0] if 'objectType' in annotations_df.columns else None\n",
    "        # There is a chance for an interception to be missed, so if there exists no records for the ID with label 'Intercepted' then there would be no object type to use, therefore don't need to plot\n",
    "        \n",
    "        if obj_type == 'Obstacle' and obj_id in obstacle_ids:\n",
    "            draw_object_line(ax, timestamp, obj_id, object_colors, is_interception=True)\n",
    "\n",
    "    return object_colors\n",
    "\n",
    "# Draw vertical lines on the given axis to represent the start and end of an experiment and scale the x axis to those timestamps\n",
    "def draw_experiment_lines(ax, start_timestamp, end_timestamp):\n",
    "    ax.axvline(x=start_timestamp, color='black', linestyle='--')\n",
    "    ax.axvline(x=end_timestamp, color='black', linestyle='--')\n",
    "    ax.set_xlim(start_timestamp, end_timestamp)\n",
    "\n",
    "# Draw a vertical line on the given axis to represent an object and add a text label.\n",
    "def draw_object_line(ax, timestamp, obj_id, object_colors, is_interception):\n",
    "    # Assign a random RGB color if ID doesn't have one\n",
    "    object_colors.setdefault(obj_id, choose_colour())\n",
    "\n",
    "    # Get the line color\n",
    "    line_color = object_colors[obj_id]\n",
    "\n",
    "    # Determine the vertical alignment and position\n",
    "    vertical_alignment = 'top' if is_interception else 'bottom'\n",
    "    vertical_position = ax.get_ylim()[0] + 0.02 if vertical_alignment == 'bottom' else ax.get_ylim()[1] - 0.02\n",
    "\n",
    "    # Plot a vertical line\n",
    "    ax.axvline(x=timestamp, color=line_color, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add text label\n",
    "    label_text = f'{\"Intercepted\" if is_interception else \"Spawned\"} {int(obj_id)} at {timestamp:.2f}'\n",
    "    ax.text(timestamp, vertical_position, label_text, rotation=90, va=vertical_alignment, ha='right', color='black')\n",
    "\n",
    "\n",
    "# Plot regions on the given axis, using colors based on the object_colors dictionary for each object ID.\n",
    "def plot_observations(ax, annotations_df, object_colours, fill_threshold=1.0):\n",
    "    looking_at_df = annotations_df.loc[annotations_df['label'] == 'Looking At'].copy()\n",
    "\n",
    "    # Create an empty dictionary to store the regions for each object ID\n",
    "    id_region_dict = {}\n",
    "\n",
    "    # Initialise variables for tracking consecutive points\n",
    "    current_obj_id = None\n",
    "    start_time = None\n",
    "\n",
    "    # Iterate through each row in the 'Looking At' dataframe\n",
    "    for _, row in looking_at_df.iterrows():\n",
    "        obj_id = row['id']\n",
    "        timestamp = row['time']\n",
    "\n",
    "        # Check if it's the same object and within the threshold seconds\n",
    "        if obj_id == current_obj_id and start_time is not None and timestamp - start_time <= fill_threshold: \n",
    "            end_time = timestamp # Update the end time for the current region\n",
    "        else:\n",
    "            # A new region is created when the next ID does not match the current region's ID OR if the time between two points is greater than the threshold (indicating it's a new region for the same ID)\n",
    "            if current_obj_id is not None and start_time is not None:\n",
    "                if current_obj_id not in id_region_dict: # If an ID has not been given regions, this will make sure that it has been intialised before we can add new regions\n",
    "                    id_region_dict[current_obj_id] = [] \n",
    "                id_region_dict[current_obj_id].append((start_time, end_time)) # Adds this region to the key with the Object ID\n",
    "\n",
    "            # Update tracking variables for the next iteration\n",
    "            current_obj_id = obj_id\n",
    "            start_time = timestamp\n",
    "            end_time = timestamp\n",
    "\n",
    "    # Add the last region after the loop\n",
    "    if current_obj_id is not None and start_time is not None:\n",
    "        if current_obj_id not in id_region_dict:\n",
    "            id_region_dict[current_obj_id] = []\n",
    "        id_region_dict[current_obj_id].append((start_time, end_time))\n",
    "\n",
    "    # Iterates through each key-value pair\n",
    "    for obj_id, regions in id_region_dict.items():\n",
    "        color = object_colours[obj_id] # Retrieves the colour of the current object from the dictionary\n",
    "\n",
    "        for region in regions: # Each region should have a start time, and an end time. We iterate through each one whiles also colouring the region between them\n",
    "            start_time, end_time = region\n",
    "            ax.axvspan(start_time, end_time, color=color, alpha=0.2, label=f'Object ID {obj_id}')\n",
    "\n",
    "# Add annotations to a given plot.\n",
    "def add_annotations(ax, offset, filepath='annotations.csv', show_observable=False):\n",
    "    if filepath:\n",
    "        # Creates a DataFrame containing all the annotation data, and also creating a new field called 'Time' which format timestamps into the corresponding time of the recording\n",
    "        annotations_df = pd.read_csv(filepath)\n",
    "        annotations_df['time'] = annotations_df['timestamp'] + offset\n",
    "        annotations_df['time'] -= annotations_df['time'].min()\n",
    "\n",
    "        # Filter annotations for 'Spawning' or 'Intercepted' labels and ObjectType 'Obstacle'\n",
    "        filtered_annotations = annotations_df[\n",
    "            (annotations_df['label'].isin(['Spawning', 'Intercepted'])) &\n",
    "            (annotations_df['objectType'] == 'Obstacle')\n",
    "        ]\n",
    "\n",
    "        # Identifying different types of annotation to plot on the graph\n",
    "        spawn_timestamps = filtered_annotations.loc[filtered_annotations['label'] == 'Spawning', 'time'].values\n",
    "        interception_timestamps = filtered_annotations.loc[filtered_annotations['label'] == 'Intercepted', 'time'].values\n",
    "\n",
    "        start_timestamp = annotations_df.loc[(annotations_df['label'] == 'Experiment Started'), 'time'].values\n",
    "        end_timestamp = annotations_df.loc[(annotations_df['label'] == 'Experiment Ended'), 'time'].values\n",
    "\n",
    "        draw_experiment_lines(ax, start_timestamp, end_timestamp) # Draws a line for when the experiment has started and ended, as well as adjusting the x-axis scale to show only between those points\n",
    "\n",
    "        # Extract ObjectType 'Obstacle' and ID for plotting\n",
    "        obstacle_ids = filtered_annotations.loc[:, 'id'].values\n",
    "\n",
    "        # Each object should be given a colour for their specific ID, this can be used for when we want to show what object the user is currently observing\n",
    "        object_colors = draw_objects_and_interceptions(ax, spawn_timestamps, interception_timestamps, annotations_df, obstacle_ids)\n",
    "        \n",
    "        # This will show regions of which indicates where the user looks at depending on the annotations with the label 'Looking At'\n",
    "        if show_observable:\n",
    "            plot_observations(ax, annotations_df, object_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying outcome of identifications and annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m gaze_filepath \u001b[38;5;241m=\u001b[39m find_gaze_csv(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Creates a DataFrame base on the csv in that filepath\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m gaze_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgaze_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Obtain the offset that helps format the annotation file\u001b[39;00m\n\u001b[0;32m      8\u001b[0m offset \u001b[38;5;241m=\u001b[39m obtain_offset(offset_filepath)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1012\u001b[0m     dialect,\n\u001b[0;32m   1013\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:472\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    470\u001b[0m ):\n\u001b[0;32m    471\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(filepath_or_buffer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    475\u001b[0m     filepath_or_buffer\u001b[38;5;241m=\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    476\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    480\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Retrieve the filepath of the csv file containing the data needed\n",
    "gaze_filepath = find_gaze_csv(os.getcwd())\n",
    "\n",
    "# Creates a DataFrame base on the csv in that filepath\n",
    "gaze_df = pd.read_csv(gaze_filepath)\n",
    "\n",
    "# Obtain the offset that helps format the annotation file\n",
    "offset = obtain_offset(offset_filepath)\n",
    "\n",
    "# Plot the eye data with required designs\n",
    "figure, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "use_smooth = True\n",
    "\n",
    "plot_angular_distance(figure, ax, gaze_df, use_smooth=use_smooth)\n",
    "plot_fixations(ax, gaze_df, use_smooth=use_smooth)\n",
    "plot_smooth_pursuits(ax, gaze_df, use_smooth=use_smooth)\n",
    "plot_saccades(ax, gaze_df, use_smooth=use_smooth)\n",
    "\n",
    "# Add the annotations to the graph\n",
    "add_annotations(ax, offset, annotations_filepath, True)\n",
    "\n",
    "# Display the graph\n",
    "figure.show()\n",
    "\n",
    "# plot_norm_positions(gaze_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
