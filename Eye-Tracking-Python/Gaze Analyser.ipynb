{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaze Analyser\n",
    "This notebook takes in three files taken from the Pupil Recordings you have exported in Pupil Player. These are:\n",
    "- `gaze_positions.csv` (contains raw data in regards to the gaze made throughout the recording)\n",
    "- `info.player.json` (contains system and sync time used to format the recording timestamps)\n",
    "- `fixations.csv` (contains events of where fixations has occured throughout the experiment)\n",
    "- `annotations.csv` (contains annotations created in the experiment used for object interception/spawn, regions of observation, and when the experiment has begin and ended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# File Paths\n",
    "info_player_filePath = 'experiment_source/info.player.json'\n",
    "gaze_csv_filePath = 'experiment_source/gaze_positions.csv'\n",
    "annotations_filepath = 'experiment_source/annotations.csv'\n",
    "fixation_filepath = 'experiment_source/fixations.csv'\n",
    "\n",
    "# Contrasting Colours\n",
    "CONTRASTING_COLURS = ['#011627', '#2ec4b6', '#e71d36', '#ff9f1c']\n",
    "current_colour_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DataFrame from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the `info.player` JSON to retrieve `start_time_synced_s` and `start_time_system_s`. This is used to format the timestamp correctly to indicate time throughout the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_offset(filepath):\n",
    "    with open(info_player_filePath, 'r') as file:\n",
    "        data = json.load(file)  \n",
    "    return data.get('start_time_system_s') - data.get('start_time_synced_s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, reading the gaze_position.csv file to obtain base data, formating time, calculating smoothed positions, and angular distance and velocity of each timestamp. And removing data that contains infinte or NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 7629 gaze positions\n"
     ]
    }
   ],
   "source": [
    "# Calculate angular distance given Cartesian coordinates (x, y)\n",
    "def calculate_angular_distance(x, y):\n",
    "    return np.arctan2(y, x)\n",
    "\n",
    "# Calculate velocity given angular distance and corresponding timestamps.\n",
    "def calculate_velocity(angular_distance, timestamp):\n",
    "    time_diff = np.diff(timestamp)\n",
    "    angular_distance_diff = np.diff(angular_distance)\n",
    "    velocity = angular_distance_diff / time_diff\n",
    "    return np.concatenate(([np.nan], velocity))\n",
    "\n",
    "\n",
    "# Applies Rolling Medium over the input field, and exports that into the output field\n",
    "def smooth_data(df, input, output, window_size=0):\n",
    "    df[output] = df[input].rolling(window=window_size).median()\n",
    "    return df\n",
    "\n",
    "def obtain_gaze_data(filepath: str, window=10, offset=0):\n",
    "    csv_df = pd.read_csv(filepath)\n",
    "    results_df = pd.DataFrame(columns=['gaze_timestamp',\n",
    "                                       'time',\n",
    "                                       'norm_pos_x', \n",
    "                                       'norm_pos_y', \n",
    "                                       'angular_distance',\n",
    "                                       'angular_velocity',\n",
    "                                       'movement_type',\n",
    "                                       'smoothed_norm_pos_x', \n",
    "                                       'smoothed_norm_pos_y',\n",
    "                                       'smoothed_angular_distance',\n",
    "                                       'smoothed_angular_velocity',\n",
    "                                       'smoothed_movement_type'])\n",
    "\n",
    "    # Copy the data from csv of necessary fields\n",
    "    results_df['gaze_timestamp'] = csv_df['gaze_timestamp']\n",
    "    results_df['norm_pos_x'] = csv_df['norm_pos_x']\n",
    "    results_df['norm_pos_y'] = csv_df['norm_pos_y']\n",
    "    results_df['movement_type'] = 'None'\n",
    "    results_df['smoothed_movement_type'] = 'None'\n",
    "    \n",
    "    # Populating the time field by adding the offset and then subtracting the minimum time to start from 0\n",
    "    results_df['time'] = results_df['gaze_timestamp'] + offset\n",
    "    results_df['time'] -= results_df['time'].min()\n",
    "\n",
    "    # Using rolling mean to smooth the data and to rmeove as many extreme outliers that has been missed by Pupil Export\n",
    "    results_df['smoothed_norm_pos_x'] = results_df['norm_pos_x'].rolling(window).median()\n",
    "    results_df['smoothed_norm_pos_y'] = results_df['norm_pos_y'].rolling(window).median()\n",
    "\n",
    "    # Calculating the angular distance for each x and y position for both smoothed and un-smoothed\n",
    "    results_df['angular_distance'] = calculate_angular_distance(results_df['norm_pos_x'], results_df['norm_pos_y'])\n",
    "    results_df['smoothed_angular_distance'] = calculate_angular_distance(results_df['smoothed_norm_pos_x'], results_df['smoothed_norm_pos_y'])\n",
    "\n",
    "    # Calculating the angular velocity for both smooth and un-smoothed angular distances over time\n",
    "    results_df['angular_velocity'] = calculate_velocity(results_df['angular_distance'], results_df['time'])\n",
    "    results_df['smoothed_angular_velocity'] = calculate_velocity(results_df['smoothed_angular_distance'], results_df['time'])\n",
    "\n",
    "    # Dropping NaN records and the `gaze_timestamp` field\n",
    "    results_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    results_df.dropna(inplace=True)\n",
    "    results_df = results_df.drop('gaze_timestamp', axis=1) # Remove the `gaze_timestamp` as that is not needed anymore\n",
    "\n",
    "    return results_df\n",
    "\n",
    "window_size=10\n",
    "offset = obtain_offset(info_player_filePath)\n",
    "gaze_df = obtain_gaze_data(gaze_csv_filePath, window=window_size, offset=offset)\n",
    "print(f'There is a total of {len(gaze_df)} gaze positions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Smooth Pursuit\n",
    "Smooth pursuit occurs when the eyes tracks an moving object. There is roughly a constant velocity as the angular distance changes slowly, whereas Saccades are almost instant. We choose regions of the line where the change in velocity is under a threshold, and the change of angular distance is small enough to indicate the eyes moving between positions slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Smooth Pursuit Movements: 5641\n"
     ]
    }
   ],
   "source": [
    "def predict_smooth_pursuit(df, threshold_velocity=0.2, angular_distance_threshold=2e-4):\n",
    "    pursuit_regions_velocity = np.abs(np.gradient(df['angular_velocity'])) < threshold_velocity\n",
    "    pursuit_regions_distance = np.abs(np.gradient(df['angular_distance'])) > angular_distance_threshold\n",
    "    pursuit_regions = (pursuit_regions_velocity) & (pursuit_regions_distance)\n",
    "    df['movement_type'] = np.where((df['movement_type'] == 'None') & pursuit_regions, 'Smooth Pursuit', df['movement_type'])\n",
    "    \n",
    "    pursuit_regions_smoothed_velocity = np.abs(np.gradient(df['smoothed_angular_velocity'])) < threshold_velocity\n",
    "    pursuit_regions_smoothed_distance = np.abs(np.gradient(df['smoothed_angular_distance'])) > angular_distance_threshold\n",
    "    pursuit_regions_smoothed = (pursuit_regions_smoothed_velocity) & (pursuit_regions_smoothed_distance)\n",
    "    df['smoothed_movement_type'] = np.where((df['smoothed_movement_type'] == 'None') & pursuit_regions_smoothed, 'Smooth Pursuit', df['smoothed_movement_type'])\n",
    "\n",
    "predict_smooth_pursuit(gaze_df, threshold_velocity=0.2, angular_distance_threshold=2e-4)\n",
    "smooth_pursuit = gaze_df[(gaze_df['movement_type'] == 'Smooth Pursuit') | (gaze_df['smoothed_movement_type'] == 'Smooth Pursuit')]\n",
    "print(f'Total Smooth Pursuit Movements: {len(smooth_pursuit)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Saccades\n",
    "Based on the research from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1190820/pdf/jphysiol00502-0164.pdf, Saccadic Movements have a stereotypical velocity graph where large peaks indicates a fast movement between two points (saccades). These are almost like straight lines between points. We can say that if the velocity between two  points exceeds a threshold, then this is most possibly a saccadic movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Saccadic Movements: 2367\n"
     ]
    }
   ],
   "source": [
    "def predict_saccades(df, threshold_velocity=0.6):\n",
    "    saccade_regions_high = df['angular_velocity'] > threshold_velocity\n",
    "    accade_regions_low = df['angular_velocity'] < -threshold_velocity\n",
    "    saccade_regions = saccade_regions_high | accade_regions_low\n",
    "    df['movement_type'] = np.where(saccade_regions, 'Saccades', 'None')\n",
    "    \n",
    "    saccade_regions_high = df['smoothed_angular_velocity'] > threshold_velocity\n",
    "    accade_regions_low = df['smoothed_angular_velocity'] < -threshold_velocity\n",
    "    saccade_regions = saccade_regions_high | accade_regions_low\n",
    "    df['smoothed_movement_type'] = np.where((df['smoothed_movement_type'].isin(['None', 'Smooth Pursuit'])) & saccade_regions, 'Saccades', df['smoothed_movement_type'])\n",
    "\n",
    "predict_saccades(gaze_df, threshold_velocity=0.6)\n",
    "saccades = gaze_df[(gaze_df['movement_type'] == 'Saccades') | (gaze_df['smoothed_movement_type'] == 'Saccades')]\n",
    "print(f'Total Saccadic Movements: {len(saccades)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Fixation\n",
    "Fixations are defined as gaze remain fixed around a stationary point. It is not directly fixed but the user gazes around the same point for a long period of time.\n",
    "\n",
    "Pupil Player provides another csv file called `fixations` which identifies the timestamp of when a fixation occurs, and how long it can take. The function `plot_fixation_graph` takes regions starting from whatever second the fixation starts up until the end of the fixation indicated by by the `duration` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Fixation Movements: 0\n"
     ]
    }
   ],
   "source": [
    "def predict_fixation(df, offset, time_offset=0.10, filepath='fixations.csv'):\n",
    "    fixations_df = pd.read_csv(filepath)\n",
    "    fixations_df['time'] = fixations_df['start_timestamp'] + offset\n",
    "    fixations_df['time'] -= fixations_df['time'].min()\n",
    "\n",
    "    for _, fixation in fixations_df.iterrows():\n",
    "        start_time = fixation['time']\n",
    "        duration = (fixation['duration'] / 1000.0) - time_offset  # Convert into seconds\n",
    "\n",
    "        # Mark rows within the fixation region as 'Fixation' in both columns\n",
    "        fixation_regions = (df['time'] >= start_time) & (df['time'] <= start_time + duration)\n",
    "        df.loc[fixation_regions, 'movement_type'] = 'Fixation'\n",
    "        df.loc[fixation_regions, 'smoothed_movement_type'] = 'Fixation'\n",
    "\n",
    "predict_fixation(gaze_df, offset, time_offset=0.10, filepath=fixation_filepath)\n",
    "fixation = gaze_df[(gaze_df['movement_type'] == 'Fixation') | (gaze_df['smoothed_movement_type'] == 'Fixation')]\n",
    "print(f'Total Fixation Movements: {len(fixation)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating Annotations\n",
    "Using the annotation.csv file, we want to generate new csv files that contains the following: object information, regions of observation, and experiment start/end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhund\\AppData\\Local\\Temp\\ipykernel_4244\\459282757.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  regions_df = pd.concat([regions_df, pd.DataFrame({'id': [current_obj_id], 'start_time': [start_time], 'end_time': [end_time]})], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "def analyse_annotations(annotations_csv_filepath, offset, fill_threshold=1):\n",
    "    # This works through the the annotation and finds the following:\n",
    "    # What object each data point is looking at\n",
    "    # When an object spawns and intercepted\n",
    "\n",
    "    # Group every spawn and interception into a single record (not all spawn may have an interception), could group by object ID?\n",
    "    annotations_df = pd.read_csv(annotations_csv_filepath)\n",
    "    \n",
    "    # Format the timestamp into time relative to the experiment\n",
    "    annotations_df['time'] = annotations_df['timestamp'] + offset\n",
    "    annotations_df['time'] -= annotations_df['time'].min()\n",
    "\n",
    "    # Filter only the data that contains 'Intercepted' or 'Spawning'.\n",
    "    # Each object has their own spawning and interception time, could create records of these two\n",
    "    # We can utilise this data as our own way to simplify the visualising and also finding TTC\n",
    "\n",
    "    # Filter rows with 'Intercepted' or 'Spawning' label\n",
    "    object_annotations = annotations_df[annotations_df['label'].isin(['Intercepted', 'Spawning'])]\n",
    "    objects_df = object_annotations.pivot(index='id', columns='label', values='time')\n",
    "    objects_df.reset_index(inplace=True)\n",
    "\n",
    "    # If any object does not have both 'Spawning' and 'Intercepted' events, fill NaN with appropriate values\n",
    "    objects_df.fillna({'spawning_timestamp': pd.NaT, 'intercepted_timestamp': pd.NaT}, inplace=True)\n",
    "\n",
    "    # Now, create a new dataframe which stores when a user is looking at a specific region\n",
    "\n",
    "    # Obtains all records with the 'Looking At' label\n",
    "    looking_at_df = annotations_df[annotations_df['label'].isin(['Looking At'])]\n",
    "\n",
    "    # Initialise an empty DataFrame to store regions\n",
    "    regions_df = pd.DataFrame(columns=['id', 'start_time', 'end_time'])\n",
    "\n",
    "    # Initialise variables for tracking consecutive points\n",
    "    current_obj_id = None\n",
    "    start_time = None\n",
    "\n",
    "    # Iterate through each row in the 'Looking At' dataframe\n",
    "    for _, row in looking_at_df.iterrows():\n",
    "        obj_id = row['id']\n",
    "        timestamp = row['time']\n",
    "\n",
    "        # Check if it's the same object and within the threshold seconds\n",
    "        if obj_id == current_obj_id and start_time is not None and timestamp - start_time <= fill_threshold: \n",
    "            end_time = timestamp # Update the end time for the current region\n",
    "        else:\n",
    "            # A new region is created when the next ID does not match the current region's ID OR if the time between two points is greater than the threshold (indicating it's a new region for the same ID)\n",
    "            if current_obj_id is not None and start_time is not None:\n",
    "                regions_df = pd.concat([regions_df, pd.DataFrame({'id': [current_obj_id], 'start_time': [start_time], 'end_time': [end_time]})], ignore_index=True)\n",
    "\n",
    "            # Update tracking variables for the next iteration\n",
    "            current_obj_id = obj_id\n",
    "            start_time = timestamp\n",
    "            end_time = timestamp\n",
    "\n",
    "    # Add the last region after the loop\n",
    "    if current_obj_id is not None and start_time is not None:\n",
    "        regions_df = pd.concat([regions_df, pd.DataFrame({'id': [current_obj_id], 'start_time': [start_time], 'end_time': [end_time]})], ignore_index=True)\n",
    "\n",
    "    # May want to include the Experiment Start and End lines as a JSON\n",
    "    start_time = annotations_df.loc[(annotations_df['label'] == 'Experiment Started'), 'time'].values\n",
    "    end_time = annotations_df.loc[(annotations_df['label'] == 'Experiment Ended'), 'time'].values\n",
    "\n",
    "    experiment_info = {\n",
    "        'Start': start_time.item(),\n",
    "        'End': end_time.item()\n",
    "    }\n",
    "\n",
    "    return objects_df, regions_df, experiment_info\n",
    "\n",
    "objects_df, regions_df, experiment_info = analyse_annotations(annotations_filepath, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding TTC per interception\n",
    "This function only works if we have incorporated the annotation as we need the interception that has been made. This iterates through each interceptiom find all the points that falls below the time that interception has been made and take the most recent saccadic movement to calculate the Time-To-Contact by taking the difference between\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_TTC(gaze_df, objects_df):\n",
    "    results = []\n",
    "\n",
    "    for index, row in objects_df.iterrows():\n",
    "        # Extract the 'Intercepted' time\n",
    "        intercepted_time = row['Intercepted']\n",
    "        \n",
    "        # Filter gaze_df based on the condition where 'time' is less than the intercepted_time\n",
    "        filtered_gaze_df = gaze_df[gaze_df['time'] < intercepted_time]\n",
    "\n",
    "        # Obtain all the records where the movement type is Saccades\n",
    "        smoothed_saccadic_gaze_df = filtered_gaze_df[filtered_gaze_df['smoothed_movement_type'] == \"Saccades\"]\n",
    "        saccadic_gaze_df = filtered_gaze_df[filtered_gaze_df['movement_type'] == \"Saccades\"]\n",
    "\n",
    "        # Obtains the latest saccadic movement before the intercepted time\n",
    "        recent_saccade = saccadic_gaze_df['time'].max()\n",
    "        smoothed_recent_saccade = smoothed_saccadic_gaze_df['time'].max()\n",
    "\n",
    "        # Calculate the saccadic movement before the interception was made which is the difference between latest saccade and interception\n",
    "        time_to_contact = intercepted_time - recent_saccade\n",
    "        smooth_time_to_contact = intercepted_time - smoothed_recent_saccade\n",
    "        results.append({\n",
    "            'Object_ID': index+1, \n",
    "            'Interception': intercepted_time, \n",
    "            'Recent Saccade': recent_saccade, \n",
    "            'Time to Contact': time_to_contact,\n",
    "            'Smoothed Recent Saccade': smoothed_recent_saccade,\n",
    "            'Smoothed Time to Contact': smooth_time_to_contact})\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "ttc_df = find_TTC(gaze_df, objects_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data\n",
    "To be used for later or with the Visualier, this exports the dataframe and an json containing the offset for annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows the dataframe to be exported as a csv file of a given name as well as a JSON file that stores the offset if the graph was to be used again\n",
    "def export_gaze_data(gaze, objects, regions, ttc, experiment_info):\n",
    "    \n",
    "    output_directory = 'analysed_output'\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    output_directory = 'visualise_source'\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Saves a copy into the analysed output\n",
    "    gaze.to_csv(f'analysed_output/gaze.csv', index=False)\n",
    "    objects.to_csv(f'analysed_output/objects.csv', index=False)\n",
    "    regions.to_csv(f'analysed_output/regions.csv', index=False)\n",
    "    ttc.to_csv(f'analysed_output/ttc.csv', index=False)\n",
    "\n",
    "    with open('analysed_output/experiment_info.json', 'w') as json_file:\n",
    "        json.dump(experiment_info, json_file)\n",
    "\n",
    "    # Saves another copy into the visualise_source \n",
    "    gaze.to_csv(f'visualise_source/gaze.csv', index=False)\n",
    "    objects.to_csv(f'visualise_source/objects.csv', index=False)\n",
    "    regions.to_csv(f'visualise_source/regions.csv', index=False)\n",
    "    ttc.to_csv(f'visualise_source/ttc.csv', index=False)\n",
    "\n",
    "    with open('visualise_source/experiment_info.json', 'w') as json_file:\n",
    "        json.dump(experiment_info, json_file)\n",
    "\n",
    "export_gaze_data(gaze_df, objects_df, regions_df, ttc_df, experiment_info) # Exporting the dataframe as a csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
